{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gKjKf2HmuI62"
   },
   "source": [
    "**Import Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VZ057C3MJVxU"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Reshape\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XwzjRR_QJsn2"
   },
   "source": [
    "*Load Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_ucAQDZJg7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169009152/169001437 [==============================] - 28s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#(X_train,y_train),(X_test,y_test) = mnist.load_data()\n",
    "#(X_train,y_train),(X_test,y_test) = fashion_mnist.load_data()\n",
    "#(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CyLjeXshKDGk"
   },
   "source": [
    "*Normalize Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4711u2t6J79X"
   },
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Autoencoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRb09w76MoDI"
   },
   "source": [
    "*Encoder Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lwcJHweQKelT"
   },
   "outputs": [],
   "source": [
    "encoder = Sequential()\n",
    "#encoder.add(Flatten(input_shape=[28,28]))\n",
    "#encoder.add(Dense(units=400,activation='relu'))\n",
    "#encoder.add(Dense(units=200,activation='relu'))\n",
    "#encoder.add(Dense(units=100,activation='relu'))\n",
    "#encoder.add(Dense(units=50,activation='relu'))\n",
    "#encoder.add(Dense(units=25,activation='relu'))\n",
    "encoder.add(Flatten(input_shape=[32,32,3]))\n",
    "encoder.add(Dense(units=1200,activation='relu'))\n",
    "encoder.add(Dense(units=600,activation='relu'))\n",
    "encoder.add(Dense(units=300,activation='relu'))\n",
    "encoder.add(Dense(units=150,activation='relu'))\n",
    "encoder.add(Dense(units=75,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uZroNycUMtsx"
   },
   "source": [
    "*Decoder Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LAJw7w69MVBG"
   },
   "outputs": [],
   "source": [
    "decoder = Sequential()\n",
    "#decoder.add(Dense(units=50,input_shape=[25],activation='relu'))\n",
    "#decoder.add(Dense(units=100,activation='relu'))\n",
    "#decoder.add(Dense(units=200,activation='relu'))\n",
    "#decoder.add(Dense(units=400,activation='relu'))\n",
    "#decoder.add(Dense(units=784,activation='sigmoid'))\n",
    "#decoder.add(Reshape([28,28]))\n",
    "decoder.add(Dense(units=150,input_shape=[75],activation='relu'))\n",
    "decoder.add(Dense(units=300,activation='relu'))\n",
    "decoder.add(Dense(units=600,activation='relu'))\n",
    "decoder.add(Dense(units=1200,activation='relu'))\n",
    "decoder.add(Dense(units=32*32*3,activation='sigmoid'))\n",
    "decoder.add(Reshape([32,32,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Autoencoder Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lXm-zzLgNPYS"
   },
   "outputs": [],
   "source": [
    "autoencoder = Sequential([encoder,decoder])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Compile Autoencoder*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ci4Iao-XNTz7"
   },
   "outputs": [],
   "source": [
    "#autoencoder.compile(loss='binary_crossentropy',optimizer=SGD(lr=1.5),metrics=['accuracy'])\n",
    "autoencoder.compile(loss='mean_squared_error',optimizer=SGD(lr=1.5),metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Train Aautoencoder*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "spPuzpAyPTh-",
    "outputId": "90e1e984-a7c5-4f69-d6fa-897caf113e0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0618 - mean_squared_error: 0.0618 - val_loss: 0.0592 - val_mean_squared_error: 0.0592\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0433 - mean_squared_error: 0.0433 - val_loss: 0.0634 - val_mean_squared_error: 0.0634\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0413 - val_mean_squared_error: 0.0413\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0324 - val_mean_squared_error: 0.0324\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0335 - val_mean_squared_error: 0.0335\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0322 - mean_squared_error: 0.0322 - val_loss: 0.0316 - val_mean_squared_error: 0.0316\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0319 - mean_squared_error: 0.0319 - val_loss: 0.0334 - val_mean_squared_error: 0.0334\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0317 - mean_squared_error: 0.0317 - val_loss: 0.0322 - val_mean_squared_error: 0.0322\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0314 - mean_squared_error: 0.0314 - val_loss: 0.0304 - val_mean_squared_error: 0.0304\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0295 - mean_squared_error: 0.0295 - val_loss: 0.0304 - val_mean_squared_error: 0.0304\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0271 - mean_squared_error: 0.0271 - val_loss: 0.0275 - val_mean_squared_error: 0.0275\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0258 - mean_squared_error: 0.0258 - val_loss: 0.0255 - val_mean_squared_error: 0.0255\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.0246 - val_mean_squared_error: 0.0246\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0241 - val_mean_squared_error: 0.0241\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0262 - val_mean_squared_error: 0.0262\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0245 - val_mean_squared_error: 0.0245\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.0239 - val_mean_squared_error: 0.0239\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0239 - val_mean_squared_error: 0.0239\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0238 - mean_squared_error: 0.0238 - val_loss: 0.0241 - val_mean_squared_error: 0.0241\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0237 - mean_squared_error: 0.0237 - val_loss: 0.0237 - val_mean_squared_error: 0.0237\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0235 - val_mean_squared_error: 0.0235\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0232 - val_mean_squared_error: 0.0232\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0230 - mean_squared_error: 0.0230 - val_loss: 0.0231 - val_mean_squared_error: 0.0231\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0231 - val_mean_squared_error: 0.0231\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.0229 - val_mean_squared_error: 0.0229\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0226 - val_mean_squared_error: 0.0226\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0225 - val_mean_squared_error: 0.0225\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.0224 - val_mean_squared_error: 0.0224\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0222 - mean_squared_error: 0.0222 - val_loss: 0.0225 - val_mean_squared_error: 0.0225\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0219 - mean_squared_error: 0.0219 - val_loss: 0.0219 - val_mean_squared_error: 0.0219\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0217 - mean_squared_error: 0.0217 - val_loss: 0.0215 - val_mean_squared_error: 0.0215\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0212 - mean_squared_error: 0.0212 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.0210 - val_mean_squared_error: 0.0210\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0204 - mean_squared_error: 0.0204 - val_loss: 0.0209 - val_mean_squared_error: 0.0209\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0202 - mean_squared_error: 0.0202 - val_loss: 0.0207 - val_mean_squared_error: 0.0207\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0199 - val_mean_squared_error: 0.0199\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.0213 - val_mean_squared_error: 0.0213\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0195 - mean_squared_error: 0.0195 - val_loss: 0.0197 - val_mean_squared_error: 0.0197\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.0199 - val_mean_squared_error: 0.0199\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.0195 - val_mean_squared_error: 0.0195\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0192 - val_mean_squared_error: 0.0192\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0191 - val_mean_squared_error: 0.0191\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0189 - mean_squared_error: 0.0189 - val_loss: 0.0196 - val_mean_squared_error: 0.0196\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0192 - val_mean_squared_error: 0.0192\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0190 - val_mean_squared_error: 0.0190\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0188 - mean_squared_error: 0.0188 - val_loss: 0.0204 - val_mean_squared_error: 0.0204\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0187 - mean_squared_error: 0.0187 - val_loss: 0.0188 - val_mean_squared_error: 0.0188\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0194 - val_mean_squared_error: 0.0194\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0190 - val_mean_squared_error: 0.0190\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0187 - val_mean_squared_error: 0.0187\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0188 - val_mean_squared_error: 0.0188\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0182 - mean_squared_error: 0.0182 - val_loss: 0.0184 - val_mean_squared_error: 0.0184\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0181 - mean_squared_error: 0.0181 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0180 - mean_squared_error: 0.0180 - val_loss: 0.0181 - val_mean_squared_error: 0.0181\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.0180 - val_mean_squared_error: 0.0180\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0178 - mean_squared_error: 0.0178 - val_loss: 0.0179 - val_mean_squared_error: 0.0179\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.0178 - val_mean_squared_error: 0.0178\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0182 - val_mean_squared_error: 0.0182\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0176 - val_mean_squared_error: 0.0176\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0172 - mean_squared_error: 0.0172 - val_loss: 0.0180 - val_mean_squared_error: 0.0180\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0167 - mean_squared_error: 0.0167 - val_loss: 0.0173 - val_mean_squared_error: 0.0173\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0177 - val_mean_squared_error: 0.0177\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0166 - mean_squared_error: 0.0166 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0164 - mean_squared_error: 0.0164 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0167 - val_mean_squared_error: 0.0167\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0170 - val_mean_squared_error: 0.0170\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0165 - val_mean_squared_error: 0.0165\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0161 - mean_squared_error: 0.0161 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0159 - mean_squared_error: 0.0159 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0180 - val_mean_squared_error: 0.0180\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 5s 4ms/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0159 - val_mean_squared_error: 0.0159\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0161 - val_mean_squared_error: 0.0161\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0162 - val_mean_squared_error: 0.0162\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n"
     ]
    }
   ],
   "source": [
    "#autoencoder.fit(X_train,X_train,epochs=100,validation_data=(X_test,X_test))\n",
    "X_train_ec = X_train*1\n",
    "X_test_ec = X_test*1\n",
    "for i in range(0,1):\n",
    "    autoencoder.fit(X_train,X_train_ec,epochs=100,validation_data=(X_test,X_test_ec))\n",
    "    X_train_ec = X_train + (X_train - autoencoder.predict(X_train))\n",
    "    X_test_ec = X_test + (X_test - autoencoder.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lossless Recovery**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([35.702118], shape=(1,), dtype=float32)\n",
      "tf.Tensor([19.567617], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.99109226], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.3766794], shape=(1,), dtype=float32)\n",
      "tf.Tensor([58.595924], shape=(1,), dtype=float32)\n",
      "tf.Tensor([19.567617], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.9999745], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.3766794], shape=(1,), dtype=float32)\n",
      "tf.Tensor([inf], shape=(1,), dtype=float32)\n",
      "tf.Tensor([19.567617], shape=(1,), dtype=float32)\n",
      "tf.Tensor([1.], shape=(1,), dtype=float32)\n",
      "tf.Tensor([0.3766794], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#for ii in range(0,10000,1):\n",
    "for ii in range(0,1,1):\n",
    "\n",
    "    # Intialization\n",
    "    x0 = X_test[ii:ii+1]*1\n",
    "    y0 = autoencoder.predict(x0[:1])\n",
    "    xu0 = tf.cast(x0*255, tf.uint8)\n",
    "    yu0 = tf.cast(y0*255, tf.uint8)\n",
    "\n",
    "    # Compensation-Mask-1\n",
    "    x = y0*1\n",
    "    y = autoencoder.predict(x[:1])\n",
    "    ex0 = x0-x\n",
    "    exu0 = tf.cast(ex0*255, tf.int16)\n",
    "    ey0 = y0-y\n",
    "    eyu0 = tf.cast(ey0*255, tf.int16)\n",
    "    eyu = eyu0*1\n",
    "\n",
    "    for k in range(1,10+1):\n",
    "        for i in range(0,32,1):\n",
    "            for j in range(0,32,1):\n",
    "                for m in range(0,3,1):\n",
    "                    #compensation-mask-1\n",
    "                    if (eyu[0][i][j][m]!=0):\n",
    "                        x[0][i][j][m] = x0[0][i][j][m] + (y0[0][i][j][m]-y[0][i][j][m])*0.1\n",
    "                        #x[0][i][j][m] = x0[0][i][j][m] + (y0[0][i][j][m]-y[0][i][j][m])*0.01\n",
    "        y = autoencoder.predict(x[:1])\n",
    "        ex = x0-x\n",
    "        ey = y0-y\n",
    "        exu = tf.cast(ex*255, tf.int16)            \n",
    "        eyu = tf.cast(ey*255, tf.int16)            \n",
    "\n",
    "    for i in range(0,32,1):\n",
    "        for j in range(0,32,1):\n",
    "            for m in range(0,3,1):\n",
    "                sum = x[0][i][j][m]\n",
    "                if (sum<0):\n",
    "                    x[0][i][j][m] = 0\n",
    "                elif (sum>1):\n",
    "                    x[0][i][j][m] = 1\n",
    "\n",
    "    xu = tf.cast(x*255, tf.uint8)       \n",
    "    yu = tf.cast(y*255, tf.uint8) \n",
    "    print(tf.image.psnr(xu,xu0,255))\n",
    "    print(tf.image.psnr(yu0,xu0,255))\n",
    "    print(tf.image.ssim(xu,xu0,255,32))\n",
    "    print(tf.image.ssim(yu0,xu0,255,32))\n",
    "\n",
    "    # Compensation-Mask-2\n",
    "    x = x*1\n",
    "    y = autoencoder.predict(x[:1])\n",
    "    ex0 = x0-x\n",
    "    exu0 = tf.cast(ex0*255, tf.int16)\n",
    "    ey0 = y0-y\n",
    "    eyu0 = tf.cast(ey0*255, tf.int16)\n",
    "    eyu = eyu0*1\n",
    "    for k in range(1,10+1):\n",
    "        for i in range(0,32,1):\n",
    "            for j in range(0,32,1):\n",
    "                for m in range(0,3,1):\n",
    "                    #compensation-mask-2\n",
    "                    if (eyu[0][i][j][m]==0):\n",
    "                        x[0][i][j][m] = x0[0][i][j][m] + (y0[0][i][j][m]-y[0][i][j][m])*0.1\n",
    "                        #x[0][i][j][m] = x0[0][i][j][m] + (y0[0][i][j][m]-y[0][i][j][m])*0.01\n",
    "        y = autoencoder.predict(x[:1])\n",
    "        ex = x0-x\n",
    "        ey = y0-y\n",
    "        exu = tf.cast(ex*255, tf.int16)            \n",
    "        eyu = tf.cast(ey*255, tf.int16)            \n",
    "\n",
    "    for i in range(0,32,1):\n",
    "        for j in range(0,32,1):\n",
    "            for m in range(0,3,1):\n",
    "                sum = x[0][i][j][m]\n",
    "                if (sum<0):\n",
    "                    x[0][i][j][m] = 0\n",
    "                elif (sum>1):\n",
    "                    x[0][i][j][m] = 1\n",
    "\n",
    "    xu = tf.cast(x*255, tf.uint8)       \n",
    "    yu = tf.cast(y*255, tf.uint8) \n",
    "    print(tf.image.psnr(xu,xu0,255))\n",
    "    print(tf.image.psnr(yu0,xu0,255))\n",
    "    print(tf.image.ssim(xu,xu0,255,32))\n",
    "    print(tf.image.ssim(yu0,xu0,255,32))\n",
    "\n",
    "    # Compensation-Nonmask\n",
    "    x = x*1\n",
    "    y = autoencoder.predict(x[:1])\n",
    "    ex0 = x0-x\n",
    "    exu0 = tf.cast(ex0*255, tf.int16)\n",
    "    ey0 = y0-y\n",
    "    eyu0 = tf.cast(ey0*255, tf.int16)\n",
    "    eyu = eyu0*1\n",
    "    for k in range(1,10+1):\n",
    "        for i in range(0,32,1):\n",
    "            for j in range(0,32,1):\n",
    "                for m in range(0,3,1):\n",
    "                    #compensation-nonmask\n",
    "                    x[0][i][j][m] = x0[0][i][j][m] + (y0[0][i][j][m]-y[0][i][j][m])*0.00001\n",
    "                    #x[0][i][j][m] = x0[0][i][j][m] + (y0[0][i][j][m]-y[0][i][j][m])*0.000001\n",
    "        y = autoencoder.predict(x[:1])\n",
    "        ex = x0-x\n",
    "        ey = y0-y\n",
    "        exu = tf.cast(ex*255, tf.int16)            \n",
    "        eyu = tf.cast(ey*255, tf.int16)            \n",
    "\n",
    "    for i in range(0,32,1):\n",
    "        for j in range(0,32,1):\n",
    "            for m in range(0,3,1):\n",
    "                sum = x[0][i][j][m]\n",
    "                if (sum<0):\n",
    "                    x[0][i][j][m] = 0\n",
    "                elif (sum>1):\n",
    "                    x[0][i][j][m] = 1\n",
    "\n",
    "    xu = tf.cast(x*255, tf.uint8)       \n",
    "    yu = tf.cast(y*255, tf.uint8) \n",
    "    print(tf.image.psnr(xu,xu0,255))\n",
    "    print(tf.image.psnr(yu0,xu0,255))\n",
    "    print(tf.image.ssim(xu,xu0,255,32))\n",
    "    print(tf.image.ssim(yu0,xu0,255,32))\n",
    "\n",
    "    # Output\n",
    "    #plt.imshow(x0[0])\n",
    "    #plt.imshow(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Autoencoders_for_mnist .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
